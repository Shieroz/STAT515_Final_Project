---
title: "STAT515_Final_Project"
author: "Phong Nguyen, Cheng-hsun Hsu, Abdullah Yusaf Khan"
date: "2025-04-29"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r message=FALSE}
# Importing libraries
library('tidyverse')
library(ggplot2)
library(dplyr)
library(glmnet)
library(randomForest)
library(tidyr)
library(tree)
library(WRS2)
library(car)
library(caret)
```
# Dataset Overview

This data set was taken from [Loan data from Lending Club](https://www.openintro.org/data/index.php?data=loans_full_schema), taken from OpenIntro. It has 55 variables and 10000 observations.

## Description

This data set represents thousands of loans made through the Lending Club platform, which is a platform that allows individuals to lend to other individuals. Of course, not all loans are created equal. Someone who is a essentially a sure bet to pay back a loan will have an easier time getting a loan with a low interest rate than someone who appears to be riskier. And for people who are very risky? They may not even get a loan offer, or they may not have accepted the loan offer due to a high interest rate. It is important to keep that last part in mind, since this data set only represents loans actually made, i.e. do not mistake this data for loan applications!

## Variables explanation

| Variable name | Variable
| - | ----- |
| emp_title | Job title |
| emp_length | Number of years in the job, rounded down. If longer than 10 years, then this is represented by the value 10 |
| state | Two-letter state code |
| homeownership | The ownership status of the applicant's residence |
| annual_income | Annual income |
| verified_income | Type of verification of the applicant's income |
| debt_to_income | Debt-to-income ratio |
| annual_income_joint | If this is a joint application, then the annual income of the two parties applying |
| verification_income_joint | Type of verification of the joint income |
| debt_to_income_joint | Debt-to-income ratio for the two parties |
| delinq_2y | Delinquencies on lines of credit in the last 2 years |
| months_since_last_delinq | Months since the last delinquency |
| earliest_credit_line | Year of the applicant's earliest line of credit |
| inquiries_last_12m | Inquiries into the applicant's credit during the last 12 months |
| total_credit_lines | Total number of credit lines in this applicant's credit history |
| open_credit_lines | Number of currently open lines of credit |
| total_credit_limit | Total available credit, e.g. if only credit cards, then the total of all the credit limits. This excludes a mortgage |
| total_credit_utilized | Total credit balance, excluding a mortgage |
| num_collections_last_12m | Number of collections in the last 12 months. This excludes medical collections |
| num_historical_failed_to_pay | The number of derogatory public records, which roughly means the number of times the applicant failed to pay |
| months_since_90d_late | Months since the last time the applicant was 90 days late on a payment |
| current_accounts_delinq | Number of accounts where the applicant is currently delinquent |
| total_collection_amount_ever | The total amount that the applicant has had against them in collections |
| current_installment_accounts | Number of installment accounts, which are (roughly) accounts with a fixed payment amount and period. A typical example might be a 36-month car loan |
| accounts_opened_24m | Number of new lines of credit opened in the last 24 months |
| months_since_last_credit_inquiry | Number of months since the last credit inquiry on this applicant |
| num_satisfactory_accounts | Number of satisfactory accounts |
| num_accounts_120d_past_due | Number of current accounts that are 120 days past due |
| num_accounts_30d_past_due | Number of current accounts that are 30 days past due |
| num_active_debit_accounts | Number of currently active bank cards |
| total_debit_limit | Total of all bank card limits |
| num_total_cc_accounts | Total number of credit card accounts in the applicant's history |
| num_open_cc_accounts | Total number of currently open credit card accounts |
| num_cc_carrying_balance | Number of credit cards that are carrying a balance |
| num_mort_accounts | Number of mortgage accounts |
| account_never_delinq_percent | Percent of all lines of credit where the applicant was never delinquent |
| tax_liens | a numeric vector |
| public_record_bankrupt | Number of bankruptcies listed in the public record for this applicant |
| loan_purpose | The category for the purpose of the loan |
| application_type | The type of application: either individual or joint |
| loan_amount | The amount of the loan the applicant received |
| term | The number of months of the loan the applicant received |
| interest_rate | Interest rate of the loan the applicant received |
| installment | Monthly payment for the loan the applicant received |
| grade | Grade associated with the loan |
| sub_grade | Detailed grade associated with the loan |
| issue_month | Month the loan was issued |
| loan_status | Status of the loan |
| initial_listing_status | Initial listing status of the loan. (has to do with whether the lender provided the entire loan or if the loan is across multiple lenders) |
| disbursement_method | Dispersement method of the loan |
| balance | Current balance on the loan |
| paid_total | Total that has been paid on the loan by the applicant |
| paid_principal | The difference between the original loan amount and the current balance on the loan |
| paid_interest | The amount of interest paid so far by the applicant |
| paid_late_fees | Late fees paid by the applicant |


# Load Data
```{r}
load('./loans_full_schema.rda')

df <- loans_full_schema
```


# Data cleaning
```{r}
df[df == ""] <- NA

# Replace the annual income with joint one if verified
df$annual_income <- ifelse(df$verification_income_joint %in% c("Verified", "Source Verified"), df$annual_income_joint, df$annual_income)
df$debt_to_income <- ifelse(df$verification_income_joint %in% c("Verified", "Source Verified"), df$debt_to_income_joint, df$debt_to_income)

df_cleaned = df[ , !names(df) %in% c('emp_title', 'annual_income_joint', 'months_since_last_delinq', 'months_since_90d_late', 'debt_to_income_joint', 'current_accounts_delinq', 'verification_income_joint', 'months_since_last_credit_inquiry')]
str(df_cleaned)

replace_emp_length <- median(na.omit(df_cleaned$emp_length)) # mean: 5.9, median: 6
df_cleaned$emp_length[is.na(df_cleaned$emp_length)] <- replace_emp_length


(colSums(is.na(df_cleaned))/nrow(df_cleaned))*100
ggplot(df_cleaned, aes(x = debt_to_income)) +
  geom_histogram(fill="cornsilk", color = "black")
 
# Replace the NA with mean
replace_debt_income <- mean(na.omit(df_cleaned$debt_to_income)) # mean: 17.43, median: 18.32
df_cleaned$debt_to_income[is.na(df_cleaned$debt_to_income)] <- replace_debt_income
df_cleaned <- na.omit(df_cleaned)
df_cleaned$state <- as.factor(df_cleaned$state)
df_cleaned$application_type <- as.factor(df_cleaned$application_type)
df_cleaned$homeownership <- as.factor(df_cleaned$homeownership)
df_cleaned$loan_purpose <- as.factor(df_cleaned$loan_purpose)
df_cleaned$loan_status <- as.factor(df_cleaned$loan_status)
df_cleaned$disbursement_method <- as.factor(df_cleaned$disbursement_method)
df_cleaned$initial_listing_status <- as.factor(df_cleaned$initial_listing_status)
df_cleaned$verified_income <- as.factor(df_cleaned$verified_income)
df_cleaned$grade <- factor(df_cleaned$grade, levels = c("A", "B", "C", "D", "E", "F", "G"), ordered=TRUE)

# Check outlier
num_cols <- sapply(df_cleaned, is.numeric)
df_num   <- df_cleaned[ , num_cols]
boxplot(df_num,
        main = "Boxplots of Numeric Columns",
        las  = 2, 
        col  = "lightgray")
outliers_list <- lapply(df_num, function(x) boxplot.stats(x)$out)
```


# Question 1: With different home-ownership is the income have significant different? 
### Using One-way ANOVA (failed)
### Reason: The residual didn't follow the normal distribution
```{r}
df_cleaned <- df_cleaned[df_cleaned$homeownership != "ANY", ]
df_cleaned <- df_cleaned %>%
  filter(homeownership != "ANY") %>%
  droplevels()
anova_result <- aov(annual_income ~ homeownership, data = df_cleaned)
qqnorm(residuals(anova_result)); qqline(residuals(anova_result))
# Try transform the data and try again
anova_trans <- df_cleaned
anova_trans$annual_income_log <- log(anova_trans$annual_income + 1)
anova_trans$annual_income_sqrt <- sqrt(anova_trans$annual_income)
# try again
anova_result <- aov(annual_income_log ~ homeownership, data = anova_trans)
qqnorm(residuals(anova_result)); qqline(residuals(anova_result))

anova_result <- aov(annual_income_sqrt ~ homeownership, data = anova_trans)
qqnorm(residuals(anova_result)); qqline(residuals(anova_result))
```

## Both fail so try nonparametric test
```{r}
table(df_cleaned$homeownership)

# Since no values for 'ANY' we remove it.
# Using Kruskal–Wallis test (nonparametric): Compares group medians by ranking all data, then testing whether rank-sums differ more than expected by chance.

kw <- kruskal.test(annual_income ~ homeownership, data = df_cleaned)
print(kw)
# Assumption:
  # 1. Independence
  # 2. Ordinal or continuous scale 
  # 3. Same‐shaped distributions under H0

boxplot(annual_income ~ homeownership, data = df_cleaned,
        main = "Boxplot of Response by Group",
        xlab = "Group", ylab = "Response")

ggplot(df, aes(x = annual_income, color = homeownership, fill = homeownership)) +
  geom_density(alpha = 0.3) +
  labs(title = "Density of annual_income by homeownership",
       x = "annual_income", y = "Density")

# By using two plots we can indicate each group have the same-shaped distributions, 
# so that differences in ranks reflect shifts in location (medians) only.
```

### Interpretation: Becasue the residuals didn't follow normalityu so we can't use the result from ANOVA. 
### We choose to use nonparametric Kruskal–Wallis. By using two plots we can said that the group have the same shape of distribution


# Question 2: Predict interest_rate 
```{r}
df_cleaned$num_open_cc_accounts <- NULL
df_cleaned$public_record_bankrupt <- NULL
df_cleaned$term <- NULL
df_cleaned$num_collections_last_12m <- NULL
numeric_cols <- sapply(df_cleaned, is.numeric)
predictors <- names(df_cleaned)[numeric_cols & names(df_cleaned) != "interest_rate"]


X <- as.matrix(df_cleaned[, predictors])
y <- df_cleaned$interest_rate

set.seed(42)
k <- 3

folds <- createFolds(y, k = k, returnTrain = FALSE)


cv_rmse <- numeric(k)
cv_mae <- numeric(k)
cv_r_squared <- numeric(k)


for (i in 1:k) {
  test_indices <- folds[[i]]
  X_train <- X[-test_indices, ]
  y_train <- y[-test_indices]
  X_test <- X[test_indices, ]
  y_test <- y[test_indices]
  
  cv_model <- cv.glmnet(X_train, y_train, alpha = 1)
  
  best_lambda <- cv_model$lambda.min
  
  predictions <- predict(cv_model, s = best_lambda, newx = X_test)
  
  rmse <- sqrt(mean((predictions - y_test)^2))
  mae <- mean(abs(predictions - y_test))
  ss_total <- sum((y_test - mean(y_test))^2)
  ss_residual <- sum((y_test - predictions)^2)
  r_squared <- 1 - (ss_residual / ss_total)
  
  cv_rmse[i] <- rmse
  cv_mae[i] <- mae
  cv_r_squared[i] <- r_squared
  
  cat("Fold", i, "- RMSE:", round(rmse, 4), "MAE:", round(mae, 4), "R²:", round(r_squared, 4), "\n")
}

avg_rmse <- mean(cv_rmse)
avg_mae <- mean(cv_mae)
avg_r_squared <- mean(cv_r_squared)

cat("\nAverage Cross-Validation Metrics:\n")
cat("RMSE:", round(avg_rmse, 4), "\n")
cat("MAE:", round(avg_mae, 4), "\n")
cat("R²:", round(avg_r_squared, 4), "\n")

final_cv_model <- cv.glmnet(X, y, alpha = 1)
final_lambda <- final_cv_model$lambda.min

plot(final_cv_model)
title("LASSO Cross-Validation")

final_model <- glmnet(X, y, alpha = 1, lambda = final_lambda)

coefs <- coef(final_model)
important_vars <- coefs[which(coefs != 0), ]
cat("\nSelected Variables and Their Coefficients:\n")
print(important_vars)

coef_df <- data.frame(
  Variable = row.names(as.matrix(coefs)),
  Coefficient = as.vector(as.matrix(coefs))
) %>% filter(Coefficient != 0)

coef_plot_data <- coef_df[-1, ]

ggplot(coef_plot_data, aes(x = reorder(Variable, abs(Coefficient)), y = Coefficient)) +
  geom_bar(stat = "identity") +
  coord_flip() +
  labs(x = "Variables", y = "Coefficient Value", 
       title = "LASSO Regression Coefficients") +
  theme_minimal()
```







# Question 3: Predict Grade by Random Forest
```{r}
# Split the data
set.seed(42)
rf_data <- df_cleaned
train_index <- sample(seq_len(nrow(rf_data)), size = 0.8 * nrow(rf_data))
train_data <- rf_data[train_index, ]
test_data  <- rf_data[-train_index, ]

rf_model <- randomForest(grade ~ ., data = train_data, importance = TRUE)
importance(rf_model)
pred <- predict(rf_model, newdata = test_data[, predictors(rf_model)])
confusionMatrix(pred, test_data$grade)
```

```{r}
ctrl <- rfeControl(functions = rfFuncs, method = "cv", number = 5)

# We first test 5, 10, 15, 20. 5 perform best then we narrow the range to 5-9
rfe_res <- rfe(
  x          = train_data[, setdiff(names(train_data), "grade")],
  y          = train_data$grade,
  sizes      = c(5, 6, 7, 8, 9),
  rfeControl = ctrl
)

predictors(rfe_res)

# re-fit on those
rf_rfe <- randomForest(grade ~ ., data = train_data[, c(predictors(rfe_res), "grade")])

# Evaluate on test data
pred <- predict(rf_rfe, newdata = test_data[, predictors(rfe_res)])
confusionMatrix(pred, test_data$grade)
```


